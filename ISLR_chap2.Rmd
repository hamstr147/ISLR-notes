---
title: "ISLR Chapter 2 solutions"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 1

**For each part (a) through (d), indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.**

a) **The sample size** ***n*** **is extremely large, and the number of predictors** ***p*** **is small.** 
A flexible model would outperform an inflexible model as overfitting is unlikely with a small number of predictors relative to observations. 

b) **The number of predictors** ***p*** **is extremely large, and the number of observations** ***n*** **is small.** An inflexible model would perform better than an inflexible model as a flexible model is likely to overfit the data. 

c) **The relationship between the predictors and response is highly non-linear.** 
A flexible model would outperform an inflexible model given a flexible model's lower bias.

d) **The variance of the error terms, i.e. $\sigma^2= Var(\epsilon)$, is extremely high.** 
An inflexible model would outperform a flexible model, given inflexible models' lower variance.

## Exercise 2

**Explain ehter each scenario is a classification or regression problem and indicate whether we are most interested in inference or prediction. Finally, provide** ***n*** **and** ***p***.

a) **We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.**
We are interested in inference, this is a regression problem, and *n* is 500 and *p* is 3.

b) **We are considering launching a new product and wish to know whether it will be a** ***success*** **or a** ***failure.*** **We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.**
We are interested in prediction, this is a classification problem, and *n* is 20 and *p* is 13.

c) **We are interested in predicting the % change in the USD/Euro exchange ratein relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the USD/Euro, the % change in the US market, the % change in the British market, and the % change in the German market.**
We are interested in prediction, this is a regression problem, and *n* is 52 and *p* is 3.

## Exercise 3

**We now revisit the bias-variance decomposition.**

a) **Provide a sketch of typical (squared) bias, variance, training error, test error, and Bayes (irreducible) error cruves, on a single plot, as we go from less flexible statistical learning methods towards more flexible approaches. The** ***x*****-axis should represent the amount of flexibility in the method, and the** ***y*****-axis should represent the values for each curve. there should be five curves. Make sure to label each one.**

b) **Explain why each of the five curves has the shape displayed in part (a).** 
Bias is high for an inflexible method but reduces as flexibility increases as more flexible models fit the data more closely. Variance will be low for an inflexible model but will increase as flexibility increases as models start to more closely (and eventually overfit) the data. The irreducible error is a fixed value for a given data set and represents the lower bound for the test error. For classification problems, the irreducible error is the proportion of points that lie on the wrong side of the Bayes decision boundary. The test error cannot go below the irreducible error but will reduce as flexibility increases, but at a certain point inflects as the model starts to overfit the data. This is the point at which the training data goes below the irreducible error (overfitting). The training error always reduces as flexibility increases as more flexible models will fit the training data more closely. 

## Exercise 4

**You will now think of some real life applications of statistical learning.**

**Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer.**

a) Whether a stock price moves up or down is an example of a predictive classification problem. We might use lagged stock prices or financial results of a company as predictors. 
b) Understanding why a member of the public votes for the Labour or Conservative party is an inferential classification problem. We might use demographic information like income, gender, religion, profession, and age as predictors.
c) Medical diagnosis is a predictive classification problem. We might have symptoms, medical history, age, and lifestyle indicators like smoker/non-smoker, level of exercise, and diet as predictors.

**Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction? Explain your answer**

a) An estate agent predicting house price movements is an example of regression where prediction is the goal. The response would be house prices and the predictors might be proximity to transport links, crime rates, proximity to good schools, number of rooms and type of property.
b) A social scientist understanding the determinants of military spending is an example of an inferential regression problem. The response would be military spending in inflation-adjusted USD, and the predictors might be country characteristics like GDP, population, number of countries it shares a border with, whether it is in an international dispute and whether it maintains military alliances.
c) A company forecasting sales is an example of a predictive regression problem. They might use lagged sales data, marketing expenditure, and economic indicators as predictors, and sales in monetary value as a response. 

**Describe three real-life applications in which cluster analysis might be useful.**

a) A marketing company segmenting customers;
b) Clustering financial transactions to identify unusual or fraudulent transactions;
c) Recommender systems for an online streaming service.

## Exercise 5

**What are the advantages and disadvantages of a very flexible (versus a less flexible) appraoch for regression or classification? Under what circumstances might a more flexible approach be preferred to a less flexible approach? When might a less flexible approach be preferred?**

A very flexible method has low bias and will fit highly non-linear data well. A less flexible approach might be preferred where there are very few observations so you may want to minimise the risk of overfitting, as a high variance method would likely result in a signficantly different model for unseen data. Less flexible methods like linear regression are more easily interpretable so might be preferred for an inference problem, while prediction might lead you to choose a more flexible model. 

## Exercise 6

**Describe the differences between a parametric and a non-parametric statistical learning approach. What are the advantages of a parametric approach to a regression or classification (as opposed to a non-parametric approach)? What are the disadvantages?**

A parametric model requires the estimation of a fixed set of values that define a function that we use to calculate outputs. An example of this is linear regression, where we estimate coefficients applied to each predictor (and a constant). A non-parametric method, like KNN, does not simplify the problem to estimating a small number of values as such a method would not make any assumptions about a specific functional form. Instead it would fit a model that closely fits the data while attempting not to overfit. A non-parametric model might perform better if the distribution of the data is unknown, as it would fit a wider range of distributions. However, to ensure that the model does not overfit, we would need a large number of observations - a small number might mean a parametric method might perform better. 

## Exercise 7

**The table below provides a training data set containing six observations, three predictors, and one qualitative response variable.**
```{r, echo=FALSE, results=TRUE}
df <- data.frame(
  X1 = c(0,2,0,0,-1,1),
  X2 = c(3,0,1,1,0,1),
  X3 = c(0,0,3,2,1,1),
  Y = c("Red", "Red", "Red", "Green", "Green", "Red"),
  stringsAsFactors = FALSE
)
print(df)
```

**Suppose we wish to use this data set to make a prediction for** ***Y*** **when** ***X_1 = X_2 = X_3 = 0*** **using** ***K*****-nearest neighbors.**

**Compute the Euclidean distance between each observation and the test point,** ***X_1 = X_2 = X_3 = 0.***
```{r}
dists <- c(3, 2, sqrt(1 + 3^2), sqrt(1 + 2^2), sqrt(1 + 1), sqrt(2 + 1))
names(dists) <- df$Y
print(dists)
```

**What is our prediction with** ***K = 1*****? Why?**
```{r}
names(dists[which(dists == min(dists))])
```
If *K = 1*, then our prediction would be Green, as this is the closest single point. 

**What is our prediction with** ***K = 3*****? Why?**
```{r}
table(names(head(sort(dists), 3)))
```
If *K = 3*, then our prediction would be Red, as two of the three closest points are Red, and just one is Green. 

**If the Bayes' decision boundary is highly non-linear, then would we expect the** ***best*** **value for** ***K*** **to be large or small? Why?**
We would expect a low K to give a better prediction, as it would fit the decision boundary more closely, which would be less linear than for a large *K*. 

## Exercise 8

**This exercise relates to the college data set, which can be found in the file** `College.csv`**. It contains a number of variables for 777 different universities and colleges in the US.**

First, load in and inspect the data.
```{r}
college <- read.csv("http://faculty.marshall.usc.edu/gareth-james/ISL/College.csv")
head(college)
```

Inspecting the data, we can see that the first column is the name of each university; as we don't want `R` to treat this column as data, we can set the row names to be this first column and remove the first column after these have been set.
```{r}
rownames(college) <- college[, 1]
college <- college[, -1]
head(college)
```

Now we can take a look at some summary statistics, pairwise plots, and boxplots to explore the data:
```{r}
summary(college)
pairs(college[, 1:10])
plot(college$Private, college$Outstate)
```

We can create a new categorical variable called `Elite` by binning the `Top10perc` variable. Then we can call `summary()` to see how many elite colleges there are and plot against `Outstate`. 
```{r}
#Create Elite variable
Elite <- rep("No", nrow(college))
Elite[college$Top10perc > 50] <- "Yes"
Elite <- as.factor(Elite)
college <- data.frame(college, Elite)

#Explore the new variable
summary(college)
plot(college$Elite, college$Outstate)
```

We can use histograms to explore the distribution of quantitative variables in the data:
```{r}
par(mfrow=c(2,2))
hist(college$Apps, breaks = 40)
hist(college$Accept, breaks = 40)
hist(college$Enroll, breaks = 20)
hist(college$Room.Board, breaks = 30)
```

Exploring the data further:
```{r}
par(mfrow = c(2,2))
plot(college$S.F.Ratio, college$Grad.Rate)
plot(college$Expend, college$Grad.Rate)
plot(college$Top25perc, college$Grad.Rate)
plot(college$P.Undergrad/(college$P.Undergrad + college$F.Undergrad), college$Grad.Rate)
```

Expenditure per student appears to have a positive impact on graduation rate, although expenditure shows diminishing returns past approximately 20,000. The relationship between the SF ratio and graduation rate seems surprisingly weak (although may be slightly negative, as expected). High school performance appears to be a good predictor of performance at college, with the top 25 per cent variable showing a correlation with graduation rate. The proportion of part time undergraduates does not appear to be storngly correlted with graduation rates. 

```{r}
par(mfrow=c(2,2))
plot(college$Private, college$perc.alumni)
plot(college$Private, college$Grad.Rate)
plot(college$Elite, college$Expend)
plot(college$Elite, college$Apps)
```

The box plots suggest that private schools tend to have higher graduation rates and that more alumni donate to them. Furthermore, elite schools get more applications and have higher levels of expenditure, as we would expect. 

```{r}
par(mfrow=c(2,2))
plot(college$Enroll, college$Accept)
plot(college$Private, college$Outstate)
plot(college$Expend, college$Personal)
plot(college$Private, college$Terminal)
```

The level of enrolment versus acceptance is very low, as shown in the first scatter plot above. We can also observe that private schools have higher levels of outstate students. Surprisingly, the level of personal expenditure is associated with lower levels of instructional expenditure. The bottom left boxplot shows that private schools have slightly lower numbers of faculty members with terminal degrees, although the distribution is quite wide. 

## Exercise 9

**This exercise involves the** `Auto` **data set. Make sure that the missing values have been removed from the data.**

Load in the Auto data set and clean out `NA` values:
```{r}
auto <- read.csv("http://faculty.marshall.usc.edu/gareth-james/ISL/Auto.csv", header = TRUE, na.strings = "?")
auto <- na.omit(auto)
```

The variables `origin` and `name` are qualitative - although the former is coded in this data set as an integer. All other variables are quantitative (although there is some ambiguity about how we should deal with certain variables - for example, the `cylinders` variable only has a small number of unique values, so could be considered a set of categories. `year` might also be considered a special case as a date variable).

```{r}
summary(auto)
```

We can quickly check the spread and average of each variable by inspecting the range, mean and standard deviation:
```{r}
sapply(auto[, 1:7], range)
sapply(auto[, 1:7], mean)
sapply(auto[, 1:7], sd)
```

Take a subset of the data by removing the 10th to 85th observations and inspect the ranges, means and standard deviations of each variable:
```{r, collapse=TRUE}
auto_subset <- auto[-c(10:85),]

print("Range")
sapply(auto_subset[1:7], range)
print("Mean")
sapply(auto_subset[1:7], mean)
print("Standard deviation")
sapply(auto_subset[1:7], sd)
```

Exploring the data using scatterplots or other tools, we can get a sense of how some variables are correlated with others:
```{r}
par(mfrow = c(2,2))
plot(auto$mpg, auto$cylinders)
plot(auto$year, auto$mpg)
plot(auto$acceleration, auto$cylinders)
plot(auto$weight, auto$mpg)
```

Number of `cylinders` is negatively correlated with `mpg` and `acceleration`. There is a clear negative relationship between `weight` and `mpg`. It also appears that cars have become more fuel efficient over time, with `mpg` increasing with `year`. 

```{r}
par(mfrow = c(1,2))
plot(as.factor(auto$origin), auto$displacement)
plot(as.factor(auto$origin), auto$mpg)
```

`origin` also appears to be a good indicator for car characteristics - European and Japanese cars have lower engine `displacement` and are more fuel efficient than their US counterparts. 

If we wanted to predict mileage (`mpg`), the plots above suggest a number of variables that would be useful in prediting `mpg`. Clear negative relationships with `weight` and number of `cylinders`, and positive relationships with `year` and non-US `origin` all suggest that these variables include useful information that could be used to predict fuel efficiency.  

## Exercise 10

**This exercise involves the** `Boston` **housing data set.**

Call the `MASS` library to load the `Boston` data set. The Boston data set has 506 observations (neighbourhoods) and 14 features (housing values and other variables).

```{r}
library(MASS)
dim(Boston)
```

Make some pairwise comparisons to inspect relationships between variables in the data:

```{r}
pairs(Boston)
```

The number of rooms (`rm`) is positively correlated with median value (`medv`), while the lower status variable (`lstat`) is strongly negatively correlated with median value (`medv`). Employment centers (`dis`) appear to be less common in residential areas. Nitrous oxide emissions (`nox`) and employment centers (`dis`) appear to be negatively correlated, although this is probably because `nox` is higher in industrial areas (`indus`), while `dis` is correlated with `zn` (areas with large areas of zoned residential land). 

On per capita crime rate (`crim`) specifically: per capita crime rate is associated with lower home values (`medv`). It is also associated with lower distance from employment centres (`dis`). Crime appears to be associated with areas with a low proportion of residential lots of over 25,000 sqft (`zn`). Areas that do not border the Charles River (`chas`) appear more likely to suffer from higher crime rates. Older buildings also appears to correlate with higher crime (`age`).

```{r}
print("Ranges")
print("crim")
range(Boston$crim)
print("ptratio")
range(Boston$ptratio)
print("tax")
range(Boston$tax)

par(mfrow = c(2,2))
hist(Boston$crim, 40)
hist(Boston$ptratio, 40)
hist(Boston$tax, 40)
```

The pairwise plots suggest that specific tax rates and ptratio values appear to correlate with high crime rates. The range for crim is very wide, as are those for tax and ptratio. The histograms show that there is a large cluster of outliers for the tax variable above a value of approximately 650, while a large number of observations appear to be in the ptratio value at just above 20, although the ptratio data appears to be more evenly distributed. Most neighborhoods seem relatively safe with low crime rates, with the distribution showing a long tail of high crime neighborhoods.

The number of suburbs in the data that bound the Charles river is:
```{r}
sum(Boston$chas)
```

The median pupil-teacher ratio in the data set is:
```{r}
median(Boston$ptratio)
```

The suburbs with the lowest median home value are:
```{r}
Boston[which(Boston$medv == min(Boston$medv)),]
```

Suburbs 399 and 406 have the joint lowest value for `medv`. THey both have thhe same `ptratio` and `tax` value, both of which sit at the upper end of each of those varaibles' ranges. However, they have markedly different crime rates - 399 has reasonably high levels of crime, but 406 is towards the upper end of the range. 

```{r}
print("lstat")
range(Boston$lstat)
print("age")
range(Boston$age)
print("indus")
range(Boston$indus)
print("zn")
range(Boston$zn)
```

Considering some other variables: lower status households (`lstat`) are both above the median value in these suburbs. They are both also at the top end of the `age` variable, suggesting they both have lots of older buildings. Both also have relatively (though not excessively) high amount of industrial land (`indus`).

The numbers of suburbs that average more than seven and eight rooms per dwelling are:
```{r}
print("More than 7:")
nrow(Boston[which(Boston$rm > 7),])

print("More than 8:")
nrow(Boston[which(Boston$rm > 8),])
```

The suburbs that average more than 8 rooms per dwelling are shown below. All suburbs with more than 8 room houses on average have a median property value that is above average for the Boston dataset. They are in low crime areas, and most are in areas where zoned lots of over 25,000ft are absent, although some do have high values on this variable, notably row 205. One area has a high amount of property for industrial use. Only one of these neighbourhoods borders the Charles river. Unsurprisingly, these areas have lower values for `lstat` (lower status of population). While most are accessible to radial highways, some have much lower indices for this predictor.
```{r}
Boston[which(Boston$rm > 8),]
```

