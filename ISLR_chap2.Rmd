---
title: "ISLR Chapter 2 exercises"
output: md_document
---
# Exercise 1

*For each part 1 through 4, indicate whether we would generally expect the performance of a flexible statistical learning method to be better or worse than an inflexible method. Justify your answer.*

1) *The sample size* n *is extremely large, and the number of predictors* p *is small.* 
A flexible model would outperform an inflexible model as the risk of overfitting with a small number of predictors relative to observations is small. 

2) *The number of predictors* p *is extremely large, and the number of observations* n *is small.* An inflexible model would perform better than an inflexible model as a flexible model is likely to overfit the data. 

3) *The relationship between the predictors and response is highly non-linear.* 
A flexible model would outperform an inflexible model given a flexible model's lower bias.

4) *The variance of the error terms, i.e.* $\sigma^2= Var(\epsilon)$*, is extremely high.* 
An inflexible model would outperform a flexible model.

# Exercise 2
a) We collect a set of data on the top 500 firms in the US. For each firm we record profit, number of employees, industry and the CEO salary. We are interested in understanding which factors affect CEO salary.

We are interested in inference, this is a regression problem, and n = 500 and p = 3.

b) We are considering launching a new product and wish to know whether it will be a success or a failure. We collect data on 20 similar products that were previously launched. For each product we have recorded whether it was a success or failure, price charged for the product, marketing budget, competition price, and ten other variables.

We are interested in prediction, this is a classification problem, and n = 20 and p = 13.

c) We are interested in predicting the % change in the US dollar in relation to the weekly changes in the world stock markets. Hence we collect weekly data for all of 2012. For each week we record the % change in the dollar, the % change in the US market, the % change in the British market, and the % change in the German market.

We are interested in prediction, this is a regression problem, and n = 52 and p = 3.

#Exercise 3
b) Bias is high for an inflexible method but reduces as flexibility increases as more flexible models fit the data more closely. Variance will be low for an inflexible model but will increase as flexibility increases as models start to overfit the data. The irreducible error is a fixed value for a given data set and represents the lower bound for the test error. For classification problems, the irreducible error is the proportion of points that lie on the wrong side of the Bayes decision boundary. The test error cannot go below the irreducible error but will reduce as flexibility increases, but at a certain point inflects as the model starts to overfit the data. This is the point at which the training data goes below the irreducible error (overfitting). The training error always reduces as flexibility increases as more flexibility will fit the training data more closely. 

#Exercise 4
a) Describe three real-life applications in which classification might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction?
- Whether a stock price moves up or down is an example of a predictive classification problem. We might use lagged stock prices or financial results of a company as predictors. 
- Understanding why a member of the public votes for the Labour or Conservative parties is an inferential classification problem. We might take demographic information like income, gender, religion, profession, and age as predictors.
- Medical diagnosis is a predictive classification problem. We might have sympotoms patients are suffering from, medical history, age, and lifestyle indicators like smoker/non-smoker, level of exercise, diet etc. as predictors.

b) Describe three real-life applications in which regression might be useful. Describe the response, as well as the predictors. Is the goal of each application inference or prediction?
- An estate agent predicting house price movements is an example of regression where prediction is the goal. The response would be house prices and the predictors might be proximity to transport links, crime rates, proximity to good schools, number of rooms and type of property.
- A social scientist understanding the determinants of military spending is an example of an inferential regression problem. The response would be military spending in inflation-adjusted USD, and the predictors might be country characteristics like GDP, population, number of countries it shares a border with, whether it is in an international dispute and whether it maintains military alliances.
- A company forecasting sales is an example of a predictive regression problem. They might use lagged sales data, marketing expenditure, and economic indicators as predictors, and sales in monetary value as a response. 

c) Describe three real-life applications in which cluster analysis might be useful.
Possible applications of cluster analysis might be:
- A marketing company segmenting customers;
- Clustering financial transactions to identify unusual transactions;
- Recommender systems for an online streaming service.

#Exercise 5
A very flexible method has low bias and will fit highly non-linear data well. A less flexible approach might be preferred where there are very few observations so you may want to minimise the risk of overfitting, as a high variance method would likely result in a signficantly different model for unseen data. Less flexible methods like linear regression are more easily interpretable so might be preferred for an inference problem, while prediction might lead you to choose a more flexible model. 

#Exercise 6
A parametric model requires the estimation of a fixed set of values that define a function that we use to calculate outputs. An example of this is linear regression, where we estimate coefficients applied to each predictor (and a constant). A non-parametric method, like KNN, does not simplify the problem to estimating a small number of values as they it would not make any assumptions about a specific functional form. Instead it would fit a model that closely fits the data while attempting not to overfit. A non-parametric model might perform better if the distribution of the data is unknown, as it would fit a wider range of distributions. However, to ensure that the model does not overfit, we would need a large number of observatins - a small number might mean a parametric method might perform better. 

#Exercise 7
```{r}
#Data
data.frame(
  X1 = c(0,2,0,0,-1,1),
  X2 = c(3,0,1,1,0,1),
  X3 = c(0,0,3,2,1,1),
  Y = c("Red", "Red", "Red", "Green", "Green", "Red"),
  stringsAsFactors = FALSE
  )

#distance from test point (0,0,0)
c(3, 2, sqrt(1 + 3^2), sqrt(1 + 2^2), sqrt(1 + 1), sqrt(2 + 1))
```

If K = 1, then our prediction would be Green, as this is the closest single point. If K = 3, then our prediction would be Red, as two of the three closest points are Red, and just one is Green. If the Bayes' decision boundary is highly non-linear, we would expect a low K to give a better prediction, as it would fit the decision boundary more closely and be less linear than a large K. 

#Exercise 8

First read in the College data set, and make the names of each college row names:

```{r}
college <- read.csv("http://faculty.marshall.usc.edu/gareth-james/ISL/College.csv")
rownames(college) <- college[, 1]
college <- college[, -1]
```

Now take a look at some summary statistics, pairwise plots, and boxplots to explore the data:

```{r}
summary(college)
pairs(college[, 1:10])
plot(college$Private, college$Outstate)
```

Now create a new categorical variable called `Elite` by binning the `Top10perc` variable. Then call `summary` to see how many elite colleges there are and plot against `Outstate`. 

```{r}
#Create Elite variable
Elite <- rep("No", nrow(college))
Elite[college$Top10perc > 50] <- "Yes"
Elite <- as.factor(Elite)
college <- data.frame(college, Elite)

#Explore the new variable
summary(college)
plot(college$Private, college$Outstate)
```

Now create histograms for quantitative variables in the dataset:

```{r}
par(mfrow=c(2,2))
hist(college$Apps, breaks = 20)
hist(college$Accept, breaks = 20)
hist(college$Enroll, breaks = 30)
hist(college$Room.Board, breaks = 50)
```

Explore the data
```{r}
par(mfrow=c(2,2))
plot(college$Expend, college$App)
plot(college$S.F.Ratio, college$App)
plot(college$P.Undergrad, college$Grad.Rate)
plot(college$Expend, college$Grad.Rate)
```

```{r}
plot(college$Private, college$perc.alumni)
```


#Exercise 9

Load in the Auto data set:

```{r}
auto <- read.csv("http://faculty.marshall.usc.edu/gareth-james/ISL/Auto.csv", header = TRUE, na.strings = "?")
auto <- na.omit(auto)
```

The variables `origin` and `name` are qualitative. All other variables are quantitative.

```{r}
summary(auto)
```

We can quickly check the spread and average of each variable by inspecting the range, mean and standard deviation:

```{r}
print("Range")
sapply(auto[, 1:7], range)
print("Mean")
sapply(auto[, 1:7], mean)
print("Standard deviation")
sapply(auto[, 1:7], sd)
```

Take a subset of the data by removing the 10th to 85th observations and inspect the ranges, means and standard deviations of each variable:

```{r}
auto_subset <- auto[-c(10:85),]

print("Range")
sapply(auto_subset[1:7], range)
print("Mean")
sapply(auto_subset[1:7], mean)
print("Standard deviation")
sapply(auto_subset[1:7], sd)
```

#Exercise 10

Call the `MASS` library to load the `Boston` data set. The Boston data set has 506 observations (neighbourhoods) and 14 features (housing values and other variables).

```{r}
library(MASS)
```

Make some pairwise comparisons to inspect relationships between variables in the data:

```{r}
pairs(Boston)
```

The following predictors appear to be correlated with crime rate: lstat, 

```{r}
sum(Boston$chas)/nrow(Boston)
```


